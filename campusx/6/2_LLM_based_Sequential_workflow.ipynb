{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb49a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()  # take environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87500c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb89cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMState(TypedDict):\n",
    "    \n",
    "    question:str\n",
    "    answer:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0074ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_qa(state:LLMState)->LLMState:\n",
    "    \n",
    "    # extract question\n",
    "    \n",
    "    question=state[\"question\"]\n",
    "    \n",
    "    # from prompt\n",
    "    prompt=f\"Answer the question: {question}\"\n",
    "    \n",
    "    # get answer from model\n",
    "    answer =model.invoke(prompt).content\n",
    "    \n",
    "    # update state\n",
    "    state[\"answer\"]=answer\n",
    "    \n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de75ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "\n",
    "graph=StateGraph(LLMState)\n",
    "\n",
    "# add node\n",
    "graph.add_node(\"llm_qa\", llm_qa)\n",
    "# edge\n",
    "graph.add_edge(START,\"llm_qa\")\n",
    "graph.add_edge(\"llm_qa\",END)\n",
    "# compile\n",
    "workflow=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83a27e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute\n",
    "initial_state={\"question\":\"What is LangGraph?\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7695ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state=workflow.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a742799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is LangGraph?',\n",
       " 'answer': 'LangGraph is a framework developed for visualizing and analyzing the connections between languages in a multilingual corpus. It uses graph-based algorithms to represent the relationships between languages based on various linguistic features, such as phonetic similarity, shared vocabulary, and grammatical structure.LangGraph allows researchers to gain insights into the similarities and differences between languages, as well as track language evolution and contact over time.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432b212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langggraphh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
